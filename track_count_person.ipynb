{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file  \n",
      "View Ultralytics Settings with 'yolo settings' or at 'C:\\Users\\masas\\AppData\\Roaming\\Ultralytics\\settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "import ultralytics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1+cpu'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect and Track and Count people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: 'yolov8_DeepSORT'\n",
      "d:\\personal_projects\\computer_vision\\yolov8_deepsort\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\personal_projects\\computer_vision\\yolov8_deepsort\\myenv\\lib\\site-packages\\IPython\\core\\magics\\osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    }
   ],
   "source": [
    "%cd yolov8_DeepSORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import time\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from PIL import Image\n",
    "import colorsys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 d:\\personal_projects\\computer_vision\\yolov8_deepsort\\images\\uav.jpg: 448x640 1 airplane, 83.9ms\n",
      "Speed: 0.0ms preprocess, 83.9ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n",
      "[4.0]\n",
      "Class: airplane\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "results = model(\"images/uav.jpg\", save = True)\n",
    "\n",
    "class_names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bbox outputs\n",
    "    probs = result.probs  # Class probabilities for classification outputs\n",
    "    cls = boxes.cls.tolist()  # Convert tensor to list\n",
    "    xyxy = boxes.xyxy\n",
    "    xywh = boxes.xywh  # box with xywh format, (N, 4)\n",
    "    conf = boxes.conf\n",
    "    print(cls)\n",
    "    for class_index in cls:\n",
    "        class_name = class_names[int(class_index)]\n",
    "        print(\"Class:\", class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepSORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep.deep_sort.utils.parser import get_config\n",
    "from deep.deep_sort.deep_sort import DeepSort\n",
    "from deep.deep_sort.sort.tracker import Tracker\n",
    "\n",
    "deep_sort_weights = 'deep/deep_sort/deep/checkpoint/ckpt.t7'\n",
    "tracker = DeepSort(model_path=deep_sort_weights, max_age=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv2\n",
    "video_path = 'images/uav_vid.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# get the video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_hight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "print(fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the codec and create VideoWritter object\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_path = 'output.mp4'\n",
    "out = cv2.VideoWriter(output_path,fourcc, fps,(frame_width,frame_hight))\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "frames = []\n",
    "\n",
    "unique_track_ids = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 1 airplane, 72.6ms\n",
      "Speed: 0.0ms preprocess, 72.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'detach'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m         class_name \u001b[38;5;241m=\u001b[39m class_names[\u001b[38;5;28mint\u001b[39m(class_idnex)]\n\u001b[0;32m     25\u001b[0m pred_cls \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m conf \u001b[38;5;241m=\u001b[39m \u001b[43mconf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     27\u001b[0m xyxy \u001b[38;5;241m=\u001b[39m xyxy\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     28\u001b[0m bboxes_xywh \u001b[38;5;241m=\u001b[39m xywh\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'detach'"
     ]
    }
   ],
   "source": [
    "\n",
    "i = 0\n",
    "counter, fps, elapsed = 0, 0, 0\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        og_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = og_frame.copy()\n",
    "\n",
    "        model = YOLO('yolov8n.pt')\n",
    "\n",
    "        results = model(frame, classes=4, conf=0.8)\n",
    "\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            probs = result.probs\n",
    "            cls = boxes.cls.tolist()\n",
    "            xyxy = boxes.xyxy\n",
    "            xywh = boxes.xywh\n",
    "            for class_idnex in cls:\n",
    "                class_name = class_names[int(class_idnex)]\n",
    "        \n",
    "        pred_cls = np.array(cls)\n",
    "        conf = conf.detach().cpu().numpy()\n",
    "        xyxy = xyxy.detach().cpu().numpy()\n",
    "        bboxes_xywh = xywh\n",
    "        bboxes_xywh = xywh.cpu().numpy()\n",
    "        bboxes_xywh = np.array(bboxes_xywh, dtype=float)\n",
    "        \n",
    "        tracks = tracker.update(bboxes_xywh, conf, og_frame)\n",
    "        \n",
    "        for track in tracker.tracker.tracks:\n",
    "            track_id = track.track_id\n",
    "            hits = track.hits\n",
    "            x1, y1, x2, y2 = track.to_tlbr()\n",
    "            w = x2 -x1\n",
    "            h = y2 - y1\n",
    "\n",
    "            red_color = (0, 0, 255)  # (B, G, R)\n",
    "            blue_color = (255, 0, 0)  # (B, G, R)\n",
    "            green_color = (0, 255, 0)  # (B, G, R)\n",
    "\n",
    "            color_id = track_id % 3\n",
    "            if color_id == 0:\n",
    "                color = red_color\n",
    "            elif color_id == 1:\n",
    "                color = blue_color\n",
    "            else:\n",
    "                color = green_color\n",
    "\n",
    "            cv2.rectangle(og_frame, (int(x1), int(y1)), (int( x1 +w) , int(y1+ h)), color, 2)\n",
    "\n",
    "            text_color = (0,0,0)\n",
    "            cv2.putText(og_frame, f\"{class_name}--{track_id}\",(int(x1) +10, int(y1) -5 ), cv2.FONT_HERSHEY_SIMPLEX, text_color,1, cv2.LINE_AA)\n",
    "\n",
    "            unique_track_ids.add(track_id)\n",
    "\n",
    "        uav_count = len(unique_track_ids)\n",
    "\n",
    "        current_time = time.perf_counter()\n",
    "        elapsed = (current_time - start_time)\n",
    "        counter +=1\n",
    "\n",
    "        if elapsed >1:\n",
    "            fps = counter/elapsed\n",
    "            counter = 0\n",
    "            start_time = current_time\n",
    "\n",
    "        cv2.putText(og_frame, f\"uav count : {uav_count}\" , (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (225,225,255), 2, cv2.LINE_AA)\n",
    "\n",
    "        frames.append(og_frame)\n",
    "\n",
    "        out.write(cv2.cvtColor(og_frame,cv2.COLOR_RGB2BGR))\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
